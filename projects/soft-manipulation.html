<!DOCTYPE html>
<html lang="en">
<head>
  <title>Nakul Vijay Nibe | Projects</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link href="https://fonts.googleapis.com/css?family=Poppins:100,200,300,400,500,600,700,800,900" rel="stylesheet">
<link rel="stylesheet" href="../css/open-iconic-bootstrap.min.css">
<link rel="stylesheet" href="../css/animate.css">
<link rel="stylesheet" href="../css/aos.css">
<link rel="stylesheet" href="../css/ionicons.min.css">
<link rel="stylesheet" href="../css/flaticon.css">
<link rel="stylesheet" href="../css/icomoon.css">
<link rel="stylesheet" href="../css/style.css">


  <style>
    .project-hero {
      padding-top: 140px;
      padding-bottom: 80px;
      text-align: center;
    }
    .project-meta {
      font-size: 14px;
      letter-spacing: 0.05em;
      opacity: 0.75;
      margin-bottom: 10px;
      text-transform: uppercase;
    }
    .project-title {
      font-size: 36px;
      font-weight: 700;
      line-height: 1.3;
    }
    .project-subtitle {
      font-size: 16px;
      opacity: 0.8;
      margin-top: 12px;
    }
    .project-section {
      margin-top: 80px;
    }
    .project-tags span {
      display: inline-block;
      margin: 6px 6px 0 0;
      padding: 6px 14px;
      border-radius: 20px;
      background: rgba(255,255,255,0.08);
      font-size: 13px;
    }
    .project-video {
      margin: 40px 0;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 25px 50px rgba(0,0,0,0.4);
    }
    .figure-grid {
      margin-top: 30px;
    }
    .figure-grid img {
      width: 100%;
      border-radius: 10px;
      box-shadow: 0 16px 30px rgba(0,0,0,0.35);
    }
    .figure-caption {
      font-size: 13px;
      opacity: 0.7;
      margin-top: 6px;
      text-align: center;
    }
    .project-divider {
      border-top: 1px solid rgba(255,255,255,0.08);
      margin: 80px 0;
    }
    table {
      background: rgba(255,255,255,0.02);
    }
  </style>
</head>

<body>

<nav class="navbar navbar-expand-lg navbar-dark ftco_navbar ftco-navbar-light fixed-top">
  <div class="container">
    <a class="navbar-brand" href="index.html">Nakul</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#ftco-nav">
      <span class="oi oi-menu"></span>
    </button>
    <div class="collapse navbar-collapse" id="ftco-nav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item"><a href="../index.html" class="nav-link">Home</a></li>
        <li class="nav-item"><a href="../index.html#projects-section" class="nav-link">Back</a></li>
        <li class="nav-item"><a href="../index.html#contact-section" class="nav-link">Contact</a></li>
      </ul>
    </div>
  </div>
</nav>

<section class="project-hero">
  <div class="container" data-aos="fade-up">
    <div class="project-meta">Robotics • Perception • Navigation</div>
    <h1 class="project-title">
      Vision-Driven Soft Manipulation:<br>
      Integrating Soft Robotics and Computer Vision
    </h1>
    <p class="project-subtitle">
      Real-time autonomous navigation and soft manipulation on a quadruped platform
    </p>
  </div>
</section>

<div class="container">

<h4>Project Poster</h4>
<p>
  The poster below summarizes the system architecture, experimental setup, and key results of the project.
</p>

<div class="row mt-4">
  <div class="col-md-12 mb-4">
    <img src="../images/soft_manip_results/soft_manipulation_poster_1.png"
         class="img-fluid rounded shadow"
         alt="Project Poster Page 1">
  </div>

  <!-- If you have a second page -->
  <!--
  <div class="col-md-12 mb-4">
    <img src="images/posters/soft_manipulation_poster_2.png"
         class="img-fluid rounded shadow"
         alt="Project Poster Page 2">
  </div>
  -->
</div>

<a href="../pdfs/vision_driven_soft_manipulation_poster.pdf"
   target="_blank"
   class="btn btn-primary mt-3">
  Download Poster (PDF)
</a>


<div class="project-video" data-aos="zoom-in">
  <video src="../videos/soft_manipulation.mp4" controls muted playsinline style="width:100%;background:#000;"></video>
</div>

<div class="project-tags text-center">
  <span>RTAB-Map</span><span>ROS Navigation</span><span>RGB-D SLAM</span>
  <span>Detectron2</span><span>VLM Verification</span><span>Soft Gripper</span>
</div>

<div class="project-section">
<h4>System Overview</h4>
<p style="text-align:justify;">
This project presents an integrated robotic framework that combines RGB-D visual SLAM, autonomous navigation, soft robotic manipulation, and object detection enhanced with Vision-Language Models (VLMs). Using RTAB-Map and the ROS Navigation Stack, a quadruped robot builds a 3D map of its environment and navigates autonomously toward target objects.

Conventional object detectors struggle in low-light or unfamiliar environments due to fixed training datasets. To address this, the system integrates Detectron2 with GPT-4.1 Vision for zero-shot verification and semantic reasoning, significantly improving robustness and generalization. Experimental results demonstrate improved localization stability, reliable navigation, and enhanced object detection performance, with DINO-DETR achieving up to 98.6% IoU and GPT-4.1 Vision identifying 41 unique objects, compared to 16 and 6 detected by MobileNetV4 and Detectron2 respectively.  
</p>

<div class="figure-block text-center">
  <img src="../images/soft_manip_results/fig1_framework.png"
       class="img-fluid mx-auto d-block"
       style="max-width:80%;">
  <div class="figure-caption">
    Figure 1. System overview.
  </div>
</div>


<div class="project-section">
<h4>SLAM & Mapping Results</h4>
<p style="text-align:justify;">
  Enforcing planar motion constraints significantly improved localization stability and map quality.
</p>

<div class="row figure-grid">
  <div class="col-md-6">
    <img src="../images/soft_manip_results/fig2_loc_before.png">
    <div class="figure-caption">Figure 2. Localization before planar constraints.</div>
  </div>
  <div class="col-md-6">
    <img src="../images/soft_manip_results/fig3_map_before.png">
    <div class="figure-caption">Figure 3. Mapping before planar constraints.</div>
  </div>
  <div class="col-md-6 mt-4">
    <img src="../images/soft_manip_results/fig4_loc_after.png">
    <div class="figure-caption">Figure 4. Localization after planar constraints.</div>
  </div>
  <div class="col-md-6 mt-4">
    <img src="../images/soft_manip_results/fig5_map_after.png">
    <div class="figure-caption">Figure 5. Mapping after planar constraints.</div>
  </div>
</div>
</div>

<div class="project-section">
<h4>Autonomous Navigation Results</h4>

<div class="row figure-grid">
  <div class="col-md-6">
    <img src="../images/soft_manip_results/fig6_paths.png">
    <div class="figure-caption">Figure 6. Global and local paths.</div>
  </div>
  <div class="col-md-6">
    <img src="../images/soft_manip_results/fig7_path_avoid.png">
    <div class="figure-caption">Figure 7. Obstacle-aware path planning.</div>
  </div>
</div>
</div>

<div class="project-section">
<h4>Object Detection Performance</h4>

<div class="table-responsive">
<table class="table table-dark table-bordered text-center">
<thead>
<tr>
<th>Model</th><th>IoU</th><th>Time</th><th>Conf</th><th>Precision</th><th>Recall</th><th>F1</th>
</tr>
</thead>
<tbody>
<tr><td>YOLOv8x</td><td>91.6</td><td>1.27</td><td>53</td><td>57.14</td><td>32.0</td><td>41.03</td></tr>
<tr><td>YOLOv11x</td><td>97.3</td><td>1.32</td><td>50</td><td>75.0</td><td>18.18</td><td>29.27</td></tr>
<tr><td><b>DINO-DETR</b></td><td><b>98.6</b></td><td>1.94</td><td>74</td><td>90.91</td><td>30.3</td><td><b>45.45</b></td></tr>
<tr><td>Detectron2</td><td>91.5</td><td>1.88</td><td><b>83</b></td><td><b>92.7</b></td><td>24.24</td><td>39.02</td></tr>
</tbody>
</table>
</div>
</div>

<div class="project-divider"></div>

<ul>
  <li>Built a real-time quadruped robot performing RGB-D SLAM and autonomous navigation.</li>
  <li>Improved perception robustness using Detectron2 + VLM verification.</li>
  <li>Selected Detectron2 for optimal speed–accuracy trade-off.</li>
</ul>

</div>

<footer class="ftco-footer ftco-section">
  <div class="container text-center">
    <p>© <script>document.write(new Date().getFullYear());</script> Nakul Vijay Nibe</p>
  </div>
</footer>

<script src="../js/jquery.min.js"></script>
<script src="../js/bootstrap.min.js"></script>
<script src="../js/aos.js"></script>
<script>AOS.init({ once:true, duration:800 });</script>

</body>
</html>
